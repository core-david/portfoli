{
  "projects": [
    {
      "id": "proj-001",
      "name": "Mexico Economic Resilience: Spatiotemporal Data Lake",
      "summary": "Serverless Medallion Data Lake on AWS orchestrating ETL pipeline with Apache Airflow and Docker to ingest 10+ years of geospatial data",
      "description": "Built a serverless Medallion Data Lake on AWS (S3, Glue, Athena), orchestrating an ETL pipeline with Apache Airflow and Docker. Engineered a distributed spatial analysis system using PySpark, implementing Uber's H3 hierarchical indexing to geocode millions of entities and calculate complex probabilistic metrics at scale.",
      "githubUrl": null,
      "demoUrl": null,
      "featured": true,
      "order": 1
    },
    {
      "id": "proj-002",
      "name": "MLOps Time Series Forecasting Pipeline",
      "summary": "Modular time series forecasting pipeline using Kedro and XGBoost with MLflow tracking and Docker containerization",
      "description": "Engineered a modular time series forecasting pipeline using Kedro and XGBoost to predict occupation levels, ensuring full reproducibility via MLflow experiment tracking and Docker containerization. Deployed an interactive Streamlit in Snowflake (SiS) dashboard.",
      "githubUrl": "https://github.com/core-david/tca-xg",
      "demoUrl": null,
      "featured": true,
      "order": 2
    },
    {
      "id": "proj-003",
      "name": "AI-Powered Public Fund Allocation System",
      "summary": "Automated scoring system using fine-tuned GPT-4o Mini to streamline public fund allocation for Government of Nuevo León",
      "description": "Architected an automated scoring system to streamline public fund allocation, ensuring consistent and bias-free evaluation. Fine-tuned GPT-4o Mini to extract insights from unstructured Excel datasets, engineering a JSONL preprocessing pipeline that achieved an F1 score of 0.75.",
      "githubUrl": null,
      "demoUrl": null,
      "featured": false,
      "order": 3
    },
    {
      "id": "proj-005",
      "name": "Gravitational Wave Detection Pipeline",
      "summary": "Topological feature extraction pipeline using Takens Embedding and CNN models to detect gravitational wave signals",
      "description": "Developed a topological feature extraction pipeline using Takens Embedding and Vietoris-Rips Persistence to train CNN models using PyTorch, distinguishing gravitational wave signals from background noise.",
      "githubUrl": "https://github.com/core-david/GW-TDA-Detection",
      "demoUrl": null,
      "featured": true,
      "order": 5
    },
    {
      "id": "proj-006",
      "name": "Environmental Pollution Classification",
      "summary": "Pollution classification model using PCA and Logistic Regression achieving 82% accuracy in PM2.5 detection",
      "description": "Engineered a pollution classification model for the Secretaría de Medio Ambiente using data from real-world environmental sensors, applying PCA and Logistic Regression to achieve 82% accuracy in PM2.5 detection.",
      "githubUrl": "https://github.com/core-david/Air-Quality-San-Nicolas",
      "demoUrl": null,
      "featured": false,
      "order": 6
    },
    {
      "id": "proj-007",
      "name": "Route Optimization System (OPTW)",
      "summary": "Multi-objective route optimization solving the Orienteering Problem with Time Windows for Government of Nuevo León",
      "description": "Formulated a multi-objective route optimization model to generate optimal itineraries, solving the Orienteering Problem with Time Windows (OPTW) subject to budget and user rating constraints. Implemented using GAMS and integrated Bing Maps API.",
      "githubUrl": "https://github.com/core-david/Tour-Orienteering-Problem-With-Time-Windows",
      "demoUrl": null,
      "featured": true,
      "order": 7
    },
    {
      "id": "proj-008",
      "name": "Industrial Failure Classification System",
      "summary": "NLP and K-Means clustering pipeline to automate classification of industrial failure reports for Ternium",
      "description": "Engineered an NLP and K-Means clustering pipeline to automate the classification of industrial failure reports, successfully handling heterogeneous text and user-generated spelling errors. Standardized the maintenance database structure.",
      "githubUrl": "https://github.com/core-david/NLP-Ternium",
      "demoUrl": null,
      "featured": false,
      "order": 8
    }
  ]
}
